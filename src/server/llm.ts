import { createOpenAI } from "@ai-sdk/openai";
import { generateObject, generateText } from "ai";
import { Ingredient, Recipe } from "../lib/types.js";
import { PromptBuilder } from "./prompts/builder.js";

const pb = new PromptBuilder({})

export function createGitHubModels() {
  const githubToken = process.env.GITHUB_TOKEN;
  if (!githubToken) {
    throw new Error("GitHub token not configured");
  }

  return createOpenAI({
    apiKey: githubToken,
    baseURL: "https://models.github.ai/inference",
  });
}

export async function generateRecipeTags({
  name,
  ingredients,
}: {
  name?: string;
  ingredients: Ingredient[];
}): Promise<string[]> {
  const githubModels = createGitHubModels();
  const p = await pb.readFile("recipe-tags");
  
  const ingredientsList = ingredients
    .map((ing) => `${ing.amount} ${ing.unit} ${ing.name}`)
    .join(", ");

  const result = await generateObject({
    model: githubModels(process.env.CHAT_MODEL || p.prompt.model),
    messages: p.messages({
      ingredients: ingredientsList,
      name_context: name ? ` and name "${name}"` : "",
    }),
    schema: p.schema,
  });

  if (!result && !result.object) {
    console.warn("No tags generated by LLM");
  }
  return result.object.tags;
}

export async function generateRecipeDescription({
  ingredients,
  name,
}: {
  ingredients: Ingredient[];
  name?: string;
}): Promise<string> {
  const githubModels = createGitHubModels();
  const p = await pb.readFile("recipe-description");

  // Create ingredient list for prompt
  const ingredientsList = ingredients
    .map((ing) => `${ing.amount} ${ing.unit} ${ing.name}`)
    .join(", ");

  const result = await generateText({
    model: githubModels(process.env.CHAT_MODEL || p.prompt.model),
    messages: p.messages({
      ingredients: ingredientsList,
      name_context: name ? ` called "${name}"` : "",
    }),
    maxTokens: 150,
    temperature: 0.9, // Add some creativity
  });

  return result.text.trim();
}

/**
 * Generate a new recipe based on liked and passed recipes using LLM
 * @param likedRecipes - Array of recipes that the user liked
 * @param passedRecipes - Array of recipes that the user passed (optional)
 * @returns Promise<Recipe> - A new recipe object generated by LLM
 */
export async function generateRecipeFromLikes({
  likedRecipes,
  passedRecipes,
}: {
  likedRecipes: Recipe[];
  passedRecipes: Recipe[];
}): Promise<Omit<Recipe, "id" | "createdAt" | "updatedAt">> {
  const githubModels = createGitHubModels();
  const p = await pb.readFile("recipe-from-likes");

  // Analyze liked recipes to understand preferences
  const likedIngredients = likedRecipes.flatMap((recipe) =>
    recipe.ingredients.map((ing) => ing.name)
  );
  const likedTags = likedRecipes.flatMap((recipe) => recipe.tags || []);

  // Format liked recipes for prompt
  const likedRecipesList = likedRecipes
    .map(
      (recipe) => `
- ${recipe.name}: ${recipe.ingredients
        .map((ing) => `${ing.amount} ${ing.unit} ${ing.name}`)
        .join(", ")}
  Glass: ${recipe.glass || "Not specified"}
  Tags: ${recipe.tags?.join(", ") || "None"}`
    )
    .join("");

  // Format disliked recipes for prompt
  const dislikedRecipesList = passedRecipes
    .map(
      (recipe) => `
- ${recipe.name}: ${recipe.ingredients
        .map((ing) => `${ing.amount} ${ing.unit} ${ing.name}`)
        .join(", ")}
  Glass: ${recipe.glass || "Not specified"}
  Tags: ${recipe.tags?.join(", ") || "None"}`
    )
    .join("");

  const result = await generateObject({
    model: githubModels(process.env.CHAT_MODEL || p.prompt.model),
    messages: p.messages({
      liked_recipes: likedRecipesList,
      disliked_recipes: dislikedRecipesList,
      common_ingredients: [...new Set(likedIngredients)]
        .slice(0, 10)
        .join(", "),
      common_tags: [...new Set(likedTags)].slice(0, 5).join(", "),
    }),
    schema: p.schema,
    maxTokens: 500,
    temperature: 0.8,
  });

  if (!result || !result.object) {
    throw new Error("Failed to generate recipe from LLM");
  }

  return {
    name: result.object.name,
    description: result.object.description,
    ingredients: result.object.ingredients as Ingredient[],
    instructions: result.object.instructions,
    glass: result.object.glass as any, // Will be validated by the schema
    garnish: result.object.garnish,
    tags: [],
  };
}

/**
 * Generate alternative ingredients for a given ingredient using LLM
 * @param ingredient - The name of the ingredient to find alternatives for
 * @returns Promise<string[]> - A list of alternative ingredients sorted by relevance
 */
export async function generateIngredientAlternatives({
  ingredient,
  recipe,
}: {
  ingredient: string;
  recipe: Recipe;
}): Promise<string[]> {
  const githubModels = createGitHubModels();
  const p = await pb.readFile("ingredient-alternatives");
  const result = await generateObject({
    model: githubModels(process.env.CHAT_MODEL || p.prompt.model),
    messages: p.messages({
      ingredient,
      "recipe.name": recipe.name,
      "recipe.description": recipe.description || "",
      "recipe.ingredients": recipe.ingredients
        .map((ing) => `${ing.amount} ${ing.unit} ${ing.name}`)
        .join(", "),
    }),
    schema: p.schema,
    maxTokens: 300,
    temperature: 0.7, // Some creativity but stay focused
  });

  if (!result || !result.object) {
    throw new Error("Failed to generate ingredient alternatives from LLM");
  }

  return result.object.alternatives;
}
